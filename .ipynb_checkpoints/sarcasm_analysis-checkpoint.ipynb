{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Sarcasm-Aware Sentiment Analysis Project\n",
        "## Real Steam Reviews Dataset Implementation\n",
        "\n",
        "This notebook implements a sarcasm detection system for Steam game reviews, combining traditional NLP techniques with gaming-specific features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install datasets transformers wordcloud vaderSentiment textblob -q\n",
        "!pip install -U scikit-learn pandas numpy matplotlib seaborn nltk -q\n",
        "\n",
        "# Import essential libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "import nltk\n",
        "import re\n",
        "from textblob import TextBlob\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "# Machine Learning imports\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (accuracy_score, classification_report, confusion_matrix, \n",
        "                           roc_auc_score, f1_score, precision_score, recall_score)\n",
        "\n",
        "# Transformer models\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Download NLTK data\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('vader_lexicon', quiet=True)\n",
        "\n",
        "# Initialize sentiment analyzers\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"‚úÖ All packages installed and imports completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_real_steam_dataset():\n",
        "    \"\"\"\n",
        "    Load real Steam Reviews dataset from multiple possible sources\n",
        "    \"\"\"\n",
        "    print(\"üì• Loading real Steam Reviews dataset...\")\n",
        "    \n",
        "    # Try multiple dataset sources\n",
        "    datasets_to_try = [\n",
        "        {\n",
        "            'source': 'kaggle',\n",
        "            'command': 'kaggle datasets download -d andrewmvd/steam-reviews --unzip',\n",
        "            'file': 'steam_reviews.csv'\n",
        "        },\n",
        "        {\n",
        "            'source': 'kaggle',\n",
        "            'command': 'kaggle datasets download -d luthfim/steam-reviews-dataset --unzip',\n",
        "            'file': 'steam_reviews.csv'\n",
        "        },\n",
        "        {\n",
        "            'source': 'kaggle', \n",
        "            'command': 'kaggle datasets download -d najzeko/steam-reviews-2021 --unzip',\n",
        "            'file': 'steam_reviews_2021.csv'\n",
        "        }\n",
        "    ]\n",
        "    \n",
        "    df = None\n",
        "    \n",
        "    for dataset in datasets_to_try:\n",
        "        try:\n",
        "            print(f\"üîÑ Trying {dataset['source']} dataset...\")\n",
        "            !{dataset['command']}\n",
        "            \n",
        "            # Try to load the file\n",
        "            df = pd.read_csv(dataset['file'])\n",
        "            print(f\"‚úÖ Successfully loaded dataset: {df.shape[0]} reviews\")\n",
        "            break\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Failed to load from {dataset['source']}: {e}\")\n",
        "            continue\n",
        "    \n",
        "    if df is None:\n",
        "        print(\"üìÅ Please upload your Steam reviews CSV file manually\")\n",
        "        print(\"Expected columns: review_text, voted_up, votes_helpful, votes_funny, playtime_forever\")\n",
        "        return None\n",
        "    \n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def identify_sarcastic_reviews(df):\n",
        "    \"\"\"\n",
        "    Identify sarcastic reviews from real Steam data using heuristics\n",
        "    \"\"\"\n",
        "    print(\"üé≠ Identifying sarcastic reviews using heuristics...\")\n",
        "    \n",
        "    # Ensure we have the right column names\n",
        "    text_column = None\n",
        "    for col in ['review', 'review_text', 'content', 'text']:\n",
        "        if col in df.columns:\n",
        "            text_column = col\n",
        "            break\n",
        "    \n",
        "    if text_column is None:\n",
        "        print(\"‚ùå Could not find review text column\")\n",
        "        return df\n",
        "    \n",
        "    # Rename to standard column name\n",
        "    df = df.rename(columns={text_column: 'review'})\n",
        "    \n",
        "    # Initialize sarcasm probability scores\n",
        "    df['sarcasm_score'] = 0.0\n",
        "    df['sarcasm_indicators'] = ''\n",
        "    \n",
        "    # Sarcasm detection heuristics\n",
        "    sarcasm_patterns = {\n",
        "        'positive_negative_mismatch': [\n",
        "            (r'(great|amazing|perfect|excellent|fantastic|wonderful|brilliant|outstanding|superb|best).*(?:crash|bug|glitch|broken|terrible|awful|horrible|worst|hate|never|not)', 2.0),\n",
        "            (r'10/10.*(?:would.*rage|crash|bug|glitch|broken|never)', 2.5),\n",
        "            (r'love.*(?:how.*crash|bug|glitch|broken|never)', 2.0)\n",
        "        ],\n",
        "        'excessive_praise_with_complaints': [\n",
        "            (r'perfect.*(?:if you enjoy|for people who|when you)', 1.5),\n",
        "            (r'amazing.*(?:graphics|sound).*(?:1995|2000|pixelated|terrible)', 2.0),\n",
        "            (r'excellent.*(?:tutorial|controls).*(?:hours|still|never|don\\'t)', 1.8)\n",
        "        ],\n",
        "        'contradictory_statements': [\n",
        "            (r'stable.*(?:crashed|crash|freeze)', 2.0),\n",
        "            (r'optimized.*(?:fps|framerate|lag|slow)', 1.8),\n",
        "            (r'balanced.*(?:overpowered|useless|broken)', 1.5)\n",
        "        ],\n",
        "        'gaming_specific_sarcasm': [\n",
        "            (r'who needs.*(?:tutorial|help|guide|instructions)', 1.5),\n",
        "            (r'nothing like.*(?:getting|being|playing)', 1.3),\n",
        "            (r'highly recommend.*(?:if you|for people who|when)', 1.2)\n",
        "        ]\n",
        "    }\n",
        "    \n",
        "    # Apply sarcasm detection patterns\n",
        "    for category, patterns in sarcasm_patterns.items():\n",
        "        for pattern, weight in patterns:\n",
        "            matches = df['review'].str.contains(pattern, case=False, na=False, regex=True)\n",
        "            df.loc[matches, 'sarcasm_score'] += weight\n",
        "            df.loc[matches, 'sarcasm_indicators'] += f\"{category}; \"\n",
        "    \n",
        "    # Additional heuristics based on Steam-specific features\n",
        "    if 'voted_up' in df.columns and 'votes_funny' in df.columns:\n",
        "        # Negative reviews with high funny votes are likely sarcastic\n",
        "        funny_negative = (df['voted_up'] == False) & (df['votes_funny'] > df['votes_funny'].quantile(0.7))\n",
        "        df.loc[funny_negative, 'sarcasm_score'] += 1.0\n",
        "        df.loc[funny_negative, 'sarcasm_indicators'] += 'funny_negative; '\n",
        "    \n",
        "    # Detect excessive punctuation and caps (sarcasm indicators)\n",
        "    df['caps_ratio'] = df['review'].apply(lambda x: sum(1 for c in str(x) if c.isupper()) / len(str(x)) if len(str(x)) > 0 else 0)\n",
        "    df['exclamation_count'] = df['review'].str.count('!')\n",
        "    df['question_count'] = df['review'].str.count('\\?')\n",
        "    \n",
        "    # High caps ratio with positive words might indicate sarcasm\n",
        "    high_caps = df['caps_ratio'] > 0.3\n",
        "    df.loc[high_caps, 'sarcasm_score'] += 0.5\n",
        "    df.loc[high_caps, 'sarcasm_indicators'] += 'high_caps; '\n",
        "    \n",
        "    # Multiple exclamation marks with negative sentiment\n",
        "    excessive_exclamation = df['exclamation_count'] > 2\n",
        "    df.loc[excessive_exclamation, 'sarcasm_score'] += 0.3\n",
        "    df.loc[excessive_exclamation, 'sarcasm_indicators'] += 'excessive_punct; '\n",
        "    \n",
        "    # Use VADER sentiment to detect polarity mismatches\n",
        "    print(\"üîç Analyzing sentiment for sarcasm detection...\")\n",
        "    sentiment_scores = df['review'].apply(lambda x: analyzer.polarity_scores(str(x)))\n",
        "    df['vader_positive'] = [score['pos'] for score in sentiment_scores]\n",
        "    df['vader_negative'] = [score['neg'] for score in sentiment_scores]\n",
        "    df['vader_compound'] = [score['compound'] for score in sentiment_scores]\n",
        "    \n",
        "    # High positive words but negative overall sentiment (potential sarcasm)\n",
        "    polarity_mismatch = (df['vader_positive'] > 0.3) & (df['vader_compound'] < -0.1)\n",
        "    df.loc[polarity_mismatch, 'sarcasm_score'] += 1.2\n",
        "    df.loc[polarity_mismatch, 'sarcasm_indicators'] += 'polarity_mismatch; '\n",
        "    \n",
        "    # Create binary sarcasm labels based on score threshold\n",
        "    sarcasm_threshold = df['sarcasm_score'].quantile(0.35)  # Top 65% as sarcastic\n",
        "    df['is_sarcastic'] = (df['sarcasm_score'] >= sarcasm_threshold).astype(int)\n",
        "    df['label'] = df['is_sarcastic']\n",
        "    df['sentiment'] = df['is_sarcastic'].map({1: 'sarcastic', 0: 'genuine'})\n",
        "    \n",
        "    print(f\"üìä Sarcasm Detection Results:\")\n",
        "    print(f\"Sarcasm threshold: {sarcasm_threshold:.2f}\")\n",
        "    print(f\"Distribution: {df['sentiment'].value_counts().to_dict()}\")\n",
        "    print(f\"Total reviews: {len(df)}\")\n",
        "    \n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_dataset_for_training(df, target_size=1200):\n",
        "    \"\"\"\n",
        "    Prepare the dataset for training with balanced sampling\n",
        "    \"\"\"\n",
        "    if df is None or len(df) == 0:\n",
        "        print(\"‚ùå No data available for training\")\n",
        "        return None\n",
        "    \n",
        "    print(f\"üìä Preparing dataset from {len(df)} reviews...\")\n",
        "    \n",
        "    # Clean the data\n",
        "    df = df.dropna(subset=['review'])\n",
        "    df = df[df['review'].str.len() > 10]  # Remove very short reviews\n",
        "    \n",
        "    # Sample data if we have too many reviews\n",
        "    if len(df) > target_size:\n",
        "        print(f\"üìâ Sampling {target_size} reviews from {len(df)} total...\")\n",
        "        \n",
        "        # Try to maintain balance between sarcastic and genuine\n",
        "        if 'label' in df.columns:\n",
        "            sarcastic_target = int(target_size * 0.65)  # 65% sarcastic\n",
        "            genuine_target = target_size - sarcastic_target\n",
        "            \n",
        "            sarcastic_reviews = df[df['label'] == 1]\n",
        "            genuine_reviews = df[df['label'] == 0]\n",
        "            \n",
        "            # Sample from each group\n",
        "            if len(sarcastic_reviews) >= sarcastic_target:\n",
        "                sarcastic_sample = sarcastic_reviews.sample(n=sarcastic_target, random_state=42)\n",
        "            else:\n",
        "                sarcastic_sample = sarcastic_reviews\n",
        "            \n",
        "            if len(genuine_reviews) >= genuine_target:\n",
        "                genuine_sample = genuine_reviews.sample(n=genuine_target, random_state=42)\n",
        "            else:\n",
        "                genuine_sample = genuine_reviews\n",
        "            \n",
        "            df = pd.concat([sarcastic_sample, genuine_sample]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "        else:\n",
        "            df = df.sample(n=target_size, random_state=42).reset_index(drop=True)\n",
        "    \n",
        "    print(f\"‚úÖ Final dataset: {len(df)} reviews\")\n",
        "    if 'sentiment' in df.columns:\n",
        "        print(f\"üìà Final distribution: {df['sentiment'].value_counts().to_dict()}\")\n",
        "    \n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SarcasmAwarePreprocessor:\n",
        "    \"\"\"\n",
        "    Advanced text preprocessor specifically designed for Steam review sarcasm detection\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "        # Preserve negation and intensifier words\n",
        "        self.preserve_words = {\n",
        "            'not', 'no', 'never', 'nothing', 'nobody', 'nowhere', 'neither', 'nor', \n",
        "            'barely', 'hardly', 'scarcely', 'very', 'so', 'extremely', 'totally', \n",
        "            'absolutely', 'completely', 'quite', 'rather', 'really', 'definitely',\n",
        "            'certainly', 'obviously', 'clearly', 'surely'\n",
        "        }\n",
        "        self.stop_words = self.stop_words - self.preserve_words\n",
        "        \n",
        "        # Steam/Gaming specific terms to preserve\n",
        "        self.gaming_terms = {\n",
        "            'dlc', 'fps', 'gameplay', 'multiplayer', 'singleplayer', 'coop', 'pvp',\n",
        "            'respawn', 'checkpoint', 'save', 'load', 'crash', 'bug', 'glitch', \n",
        "            'lag', 'ping', 'server', 'patch', 'update', 'nerf', 'buff', 'op',\n",
        "            'ragequit', 'noob', 'pro', 'speedrun', 'achievements', 'trophies'\n",
        "        }\n",
        "    \n",
        "    def extract_advanced_sarcasm_features(self, text):\n",
        "        \"\"\"\n",
        "        Extract comprehensive sarcasm detection features\n",
        "        \"\"\"\n",
        "        if not isinstance(text, str):\n",
        "            text = str(text)\n",
        "        \n",
        "        features = {}\n",
        "        text_lower = text.lower()\n",
        "        words = text.split()\n",
        "        \n",
        "        # Basic text statistics\n",
        "        features['word_count'] = len(words)\n",
        "        features['char_count'] = len(text)\n",
        "        features['avg_word_length'] = np.mean([len(word) for word in words]) if words else 0\n",
        "        features['sentence_count'] = len(re.split(r'[.!?]+', text))\n",
        "        \n",
        "        # Capitalization patterns (often used in sarcasm)\n",
        "        features['caps_ratio'] = sum(1 for c in text if c.isupper()) / len(text) if text else 0\n",
        "        features['caps_words'] = sum(1 for word in words if word.isupper())\n",
        "        features['caps_sequences'] = len(re.findall(r'[A-Z]{3,}', text))\n",
        "        \n",
        "        # Punctuation patterns (excessive punctuation in sarcasm)\n",
        "        features['exclamation_count'] = text.count('!')\n",
        "        features['question_count'] = text.count('?')\n",
        "        features['ellipsis_count'] = len(re.findall(r'\\.{3,}', text))\n",
        "        features['multiple_punct'] = len(re.findall(r'[!?]{2,}', text))\n",
        "        features['punct_density'] = sum([features['exclamation_count'], features['question_count'], \n",
        "                                       features['ellipsis_count']]) / len(text) if text else 0\n",
        "        \n",
        "        # Sentiment analysis scores\n",
        "        sentiment_scores = analyzer.polarity_scores(text)\n",
        "        features.update({f'vader_{k}': v for k, v in sentiment_scores.items()})\n",
        "        \n",
        "        # Advanced sarcasm indicators\n",
        "        features['intensifier_count'] = sum(1 for word in text_lower.split() \n",
        "                                          if word in ['very', 'so', 'extremely', 'totally', 'absolutely', \n",
        "                                                    'completely', 'quite', 'rather', 'really', 'definitely'])\n",
        "        \n",
        "        # Contradiction patterns\n",
        "        positive_words = ['great', 'amazing', 'excellent', 'fantastic', 'wonderful', 'perfect', \n",
        "                         'brilliant', 'outstanding', 'superb', 'best', 'love', 'awesome']\n",
        "        negative_words = ['terrible', 'awful', 'horrible', 'worst', 'hate', 'broken', 'crash', \n",
        "                         'bug', 'glitch', 'frustrating', 'annoying', 'impossible']\n",
        "        \n",
        "        features['positive_word_count'] = sum(1 for word in positive_words if word in text_lower)\n",
        "        features['negative_word_count'] = sum(1 for word in negative_words if word in text_lower)\n",
        "        features['pos_neg_cooccurrence'] = 1 if features['positive_word_count'] > 0 and features['negative_word_count'] > 0 else 0\n",
        "        \n",
        "        # Steam-specific sarcasm patterns\n",
        "        steam_sarcasm_patterns = [\n",
        "            r'10/10.*would.*(?:rage|quit|crash|never)',\n",
        "            r'perfect.*(?:if you enjoy|for people who)',\n",
        "            r'great.*(?:if you like|when you)',\n",
        "            r'love.*how.*(?:crash|bug|glitch)',\n",
        "            r'amazing.*(?:graphics|sound).*(?:from|like).*(?:199\\d|200\\d)',\n",
        "            r'excellent.*(?:tutorial|help).*(?:hours|still|never)',\n",
        "            r'who needs.*(?:tutorial|help|balance)',\n",
        "            r'nothing like.*getting.*(?:owned|destroyed|rekt)',\n",
        "            r'highly recommend.*(?:if you|for people who).*(?:enjoy|like).*(?:pain|suffering|frustration)'\n",
        "        ]\n",
        "        \n",
        "        features['steam_sarcasm_count'] = sum(1 for pattern in steam_sarcasm_patterns \n",
        "                                            if re.search(pattern, text_lower))\n",
        "        \n",
        "        # Gaming terminology\n",
        "        features['gaming_terms_count'] = sum(1 for term in self.gaming_terms if term in text_lower)\n",
        "        \n",
        "        # Quotation marks (often used sarcastically)\n",
        "        features['quote_count'] = text.count('\"') + text.count(\"'\")\n",
        "        \n",
        "        # All caps words (emphasis in sarcasm)\n",
        "        features['all_caps_words'] = len(re.findall(r'\\b[A-Z]{2,}\\b', text))\n",
        "        \n",
        "        return features\n",
        "    \n",
        "    def preprocess_text(self, text):\n",
        "        \"\"\"\n",
        "        Comprehensive text preprocessing for sarcasm detection\n",
        "        \"\"\"\n",
        "        if not isinstance(text, str):\n",
        "            text = str(text)\n",
        "        \n",
        "        # Extract features before preprocessing\n",
        "        features = self.extract_advanced_sarcasm_features(text)\n",
        "        \n",
        "        # Preserve important patterns before cleaning\n",
        "        text = re.sub(r'(\\d+)/(\\d+)', r'RATING_\\1_\\2', text)  # Preserve ratings like 10/10\n",
        "        text = re.sub(r'[.]{3,}', ' ELLIPSIS ', text)\n",
        "        text = re.sub(r'[!]{2,}', ' MULTIPLE_EXCLAMATION ', text)\n",
        "        text = re.sub(r'[?]{2,}', ' MULTIPLE_QUESTION ', text)\n",
        "        \n",
        "        # Clean URLs, mentions, etc.\n",
        "        text = re.sub(r'http\\S+', '', text)\n",
        "        text = re.sub(r'@\\w+', '', text)\n",
        "        text = re.sub(r'#\\w+', '', text)\n",
        "        \n",
        "        # Preserve negation context\n",
        "        negation_patterns = [\n",
        "            (r'\\b(not|no|never|nothing|nobody|nowhere|neither|nor)\\s+(\\w+)', r'\\1_\\2'),\n",
        "            (r'\\b(barely|hardly|scarcely)\\s+(\\w+)', r'\\1_\\2'),\n",
        "            (r'\\b(can\\'t|cannot|won\\'t|wouldn\\'t|shouldn\\'t|couldn\\'t)\\s+(\\w+)', r'\\1_\\2'),\n",
        "            (r'\\b(don\\'t|doesn\\'t|didn\\'t)\\s+(\\w+)', r'\\1_\\2')\n",
        "        ]\n",
        "        \n",
        "        for pattern, replacement in negation_patterns:\n",
        "            text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)\n",
        "        \n",
        "        # Tokenize and clean\n",
        "        tokens = nltk.word_tokenize(text.lower())\n",
        "        \n",
        "        # Remove stopwords but preserve important words\n",
        "        tokens = [token for token in tokens \n",
        "                 if token not in self.stop_words or token in self.preserve_words or token in self.gaming_terms]\n",
        "        \n",
        "        # Keep alphabetic tokens and preserved special tokens\n",
        "        special_tokens = ['ELLIPSIS', 'MULTIPLE_EXCLAMATION', 'MULTIPLE_QUESTION'] + [f'RATING_{i}_{j}' for i in range(1, 11) for j in range(1, 11)]\n",
        "        tokens = [token for token in tokens \n",
        "                 if token.isalpha() or token in special_tokens or '_' in token]\n",
        "        \n",
        "        clean_text = ' '.join(tokens)\n",
        "        \n",
        "        return clean_text, features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def main():\n",
        "    \"\"\"\n",
        "    Main execution pipeline for real Steam reviews sarcasm detection\n",
        "    \"\"\"\n",
        "    print(\"üöÄ Starting Real Steam Reviews Sarcasm Detection Pipeline\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Step 1: Load real dataset\n",
        "    df_raw = load_real_steam_dataset()\n",
        "    \n",
        "    if df_raw is None:\n",
        "        print(\"‚ùå Could not load dataset. Please check your setup.\")\n",
        "        return\n",
        "    \n",
        "    print(f\"\\nüìä Raw dataset loaded: {df_raw.shape}\")\n",
        "    print(f\"Columns: {list(df_raw.columns)}\")\n",
        "    \n",
        "    # Step 2: Identify sarcastic reviews\n",
        "    df_labeled = identify_sarcastic_reviews(df_raw)\n",
        "    \n",
        "    # Step 3: Prepare for training\n",
        "    df = prepare_dataset_for_training(df_labeled, target_size=1200)\n",
        "    \n",
        "    if df is None:\n",
        "        print(\"‚ùå Could not prepare dataset for training.\")\n",
        "        return\n",
        "    \n",
        "    # Step 4: Advanced preprocessing\n",
        "    print(\"\\nüîß Applying advanced preprocessing...\")\n",
        "    preprocessor = SarcasmAwarePreprocessor()\n",
        "    \n",
        "    results = df['review'].apply(lambda x: preprocessor.preprocess_text(x))\n",
        "    df['clean_review'] = [result[0] for result in results]\n",
        "    features_list = [result[1] for result in results]\n",
        "    \n",
        "    # Convert features to DataFrame\n",
        "    features_df = pd.DataFrame(features_list)\n",
        "    df = pd.concat([df, features_df], axis=1)\n",
        "    \n",
        "    print(f\"‚úÖ Preprocessing completed!\")\n",
        "    print(f\"Added {len(features_df.columns)} advanced features\")\n",
        "    \n",
        "    # Step 5: Create feature matrix\n",
        "    print(\"\\nüéØ Creating feature matrices...\")\n",
        "    \n",
        "    # TF-IDF features\n",
        "    tfidf = TfidfVectorizer(\n",
        "        max_features=3000,\n",
        "        ngram_range=(1, 3),\n",
        "        min_df=2,\n",
        "        max_df=0.9,\n",
        "        sublinear_tf=True\n",
        "    )\n",
        "    \n",
        "    X_tfidf = tfidf.fit_transform(df['clean_review'])\n",
        "    \n",
        "    # Numerical features\n",
        "    feature_cols = [col for col in features_df.columns if isinstance(df[col].iloc[0], (int, float))]\n",
        "    X_numerical = df[feature_cols].fillna(0)\n",
        "    \n",
        "    # Combine features\n",
        "    from scipy.sparse import hstack\n",
        "    import scipy.sparse as sp\n",
        "    X_combined = hstack([X_tfidf, sp.csr_matrix(X_numerical.values)])\n",
        "    \n",
        "    y = df['label'].values\n",
        "    \n",
        "    print(f\"üìà Feature matrix shape: {X_combined.shape}\")\n",
        "    print(f\"üè∑Ô∏è Label distribution: Sarcastic: {sum(y)}, Genuine: {len(y) - sum(y)}\")\n",
        "    \n",
        "    # Step 6: Train models\n",
        "    print(\"\\nü§ñ Training models...\")\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_combined, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "    \n",
        "    models = {\n",
        "        'Naive Bayes': MultinomialNB(alpha=0.1),\n",
        "        'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000, C=1.0),\n",
        "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)\n",
        "    }\n",
        "    \n",
        "    results = {}\n",
        "    \n",
        "    for name, model in models.items():\n",
        "        print(f\"Training {name}...\")\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        \n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred)\n",
        "        recall = recall_score(y_test, y_pred)\n",
        "        \n",
        "        results[name] = {\n",
        "            'Accuracy': accuracy,\n",
        "            'F1-Score': f1,\n",
        "            'Precision': precision,\n",
        "            'Recall': recall\n",
        "        }\n",
        "        \n",
        "        print(f\"‚úÖ {name} - Accuracy: {accuracy:.3f}, F1: {f1:.3f}\")\n",
        "    \n",
        "    # Step 7: Display results\n",
        "    print(\"\\nüìä FINAL RESULTS:\")\n",
        "    print(\"=\" * 50)\n",
        "    results_df = pd.DataFrame(results).round(3)\n",
        "    print(results_df)\n",
        "    \n",
        "    # Find best model\n",
        "    best_model = results_df.loc['F1-Score'].idxmax()\n",
        "    best_f1 = results_df.loc['F1-Score', best_model]\n",
        "    \n",
        "    print(f\"\\nüèÜ Best Model: {best_model}\")\n",
        "    print(f\"üéØ Best F1 Score: {best_f1}\")\n",
        "    \n",
        "    # Step 8: Show example predictions\n",
        "    print(\"\\nüîç Example Predictions:\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    best_model_obj = models[best_model]\n",
        "    sample_indices = np.random.choice(len(X_test), 5, replace=False)\n",
        "    \n",
        "    for idx in sample_indices:\n",
        "        prediction = best_model_obj.predict(X_test[idx])[0]\n",
        "        actual = y_test[idx]\n",
        "        review_text = df.iloc[X_test.indices[idx] if hasattr(X_test, 'indices') else idx]['review'][:100]\n",
        "        \n",
        "        print(f\"Review: {review_text}...\")\n",
        "        print(f\"Predicted: {'Sarcastic' if prediction == 1 else 'Genuine'}\")\n",
        "        print(f\"Actual: {'Sarcastic' if actual == 1 else 'Genuine'}\")\n",
        "        print(\"-\" * 40)\n",
        "    \n",
        "    print(\"\\nüéâ Analysis completed successfully!\")\n",
        "    \n",
        "    return df, results_df, models[best_model]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run the main pipeline\n",
        "if __name__ == \"__main__\":\n",
        "    df_final, results_final, best_model_final = main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
