{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Sarcasm-Aware Sentiment Analysis Project\n",
    "## Real Steam Reviews Dataset Implementation\n",
    "\n",
    "This notebook implements a sarcasm detection system for Steam game reviews, combining traditional NLP techniques with gaming-specific features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "statsmodels 0.14.2 requires packaging>=21.3, but you have packaging 20.9 which is incompatible.\n",
      "streamlit 1.32.0 requires protobuf<5,>=3.20, but you have protobuf 5.28.2 which is incompatible.\n",
      "xarray 2023.6.0 requires packaging>=21.3, but you have packaging 20.9 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mâœ… All packages installed and imports completed!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install datasets transformers wordcloud vaderSentiment textblob -q\n",
    "!pip install -U scikit-learn pandas numpy matplotlib seaborn nltk -q\n",
    "\n",
    "# Import essential libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Machine Learning imports\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, classification_report, confusion_matrix, \n",
    "                           roc_auc_score, f1_score, precision_score, recall_score)\n",
    "\n",
    "# Transformer models\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('vader_lexicon', quiet=True)\n",
    "\n",
    "# Initialize sentiment analyzers\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"âœ… All packages installed and imports completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_real_steam_dataset():\n",
    "    \"\"\"\n",
    "    Load real Steam Reviews dataset from the local CSV file\n",
    "    \"\"\"\n",
    "    print(\"ðŸ“¥ Loading Steam Reviews dataset...\")\n",
    "    \n",
    "    try:\n",
    "        # Load the dataset\n",
    "        df = pd.read_csv('steam_reviews.csv')\n",
    "        \n",
    "        # Rename columns to match our expected format\n",
    "        df = df.rename(columns={\n",
    "            'review': 'review_text',\n",
    "            'funny': 'votes_funny',\n",
    "            'helpful': 'votes_helpful',\n",
    "            'hour_played': 'playtime_forever',\n",
    "            'recommendation': 'voted_up'\n",
    "        })\n",
    "        \n",
    "        # Convert recommendation to boolean\n",
    "        df['voted_up'] = df['voted_up'].apply(lambda x: True if x == 'Recommended' else False)\n",
    "        \n",
    "        # Convert playtime to float (in case it's string)\n",
    "        df['playtime_forever'] = pd.to_numeric(df['playtime_forever'], errors='coerce')\n",
    "        \n",
    "        print(f\"âœ… Successfully loaded dataset: {df.shape[0]} reviews\")\n",
    "        print(\"\\nSample review:\")\n",
    "        print(df[['review_text', 'voted_up', 'votes_funny', 'votes_helpful', 'playtime_forever']].iloc[0])\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading dataset: {e}\")\n",
    "        print(\"\\nðŸ“ Please ensure your CSV file is named 'steam_reviews.csv' and contains the following columns:\")\n",
    "        print(\"- date_posted\")\n",
    "        print(\"- funny\")\n",
    "        print(\"- helpful\")\n",
    "        print(\"- hour_played\")\n",
    "        print(\"- is_early_access_review\")\n",
    "        print(\"- recommendation\")\n",
    "        print(\"- review\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_sarcastic_reviews(df):\n",
    "    \"\"\"\n",
    "    Identify sarcastic reviews from real Steam data using heuristics\n",
    "    \"\"\"\n",
    "    print(\"ðŸŽ­ Identifying sarcastic reviews using heuristics...\")\n",
    "    \n",
    "    # Ensure we have the right column names\n",
    "    text_column = None\n",
    "    for col in ['review', 'review_text', 'content', 'text']:\n",
    "        if col in df.columns:\n",
    "            text_column = col\n",
    "            break\n",
    "    \n",
    "    if text_column is None:\n",
    "        print(\"âŒ Could not find review text column\")\n",
    "        return df\n",
    "    \n",
    "    # Rename to standard column name\n",
    "    df = df.rename(columns={text_column: 'review'})\n",
    "    \n",
    "    # Initialize sarcasm probability scores\n",
    "    df['sarcasm_score'] = 0.0\n",
    "    df['sarcasm_indicators'] = ''\n",
    "    \n",
    "    # Sarcasm detection heuristics\n",
    "    sarcasm_patterns = {\n",
    "        'positive_negative_mismatch': [\n",
    "            (r'(great|amazing|perfect|excellent|fantastic|wonderful|brilliant|outstanding|superb|best).*(?:crash|bug|glitch|broken|terrible|awful|horrible|worst|hate|never|not)', 2.0),\n",
    "            (r'10/10.*(?:would.*rage|crash|bug|glitch|broken|never)', 2.5),\n",
    "            (r'love.*(?:how.*crash|bug|glitch|broken|never)', 2.0)\n",
    "        ],\n",
    "        'excessive_praise_with_complaints': [\n",
    "            (r'perfect.*(?:if you enjoy|for people who|when you)', 1.5),\n",
    "            (r'amazing.*(?:graphics|sound).*(?:1995|2000|pixelated|terrible)', 2.0),\n",
    "            (r'excellent.*(?:tutorial|controls).*(?:hours|still|never|don\\'t)', 1.8)\n",
    "        ],\n",
    "        'contradictory_statements': [\n",
    "            (r'stable.*(?:crashed|crash|freeze)', 2.0),\n",
    "            (r'optimized.*(?:fps|framerate|lag|slow)', 1.8),\n",
    "            (r'balanced.*(?:overpowered|useless|broken)', 1.5)\n",
    "        ],\n",
    "        'gaming_specific_sarcasm': [\n",
    "            (r'who needs.*(?:tutorial|help|guide|instructions)', 1.5),\n",
    "            (r'nothing like.*(?:getting|being|playing)', 1.3),\n",
    "            (r'highly recommend.*(?:if you|for people who|when)', 1.2)\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Apply sarcasm detection patterns\n",
    "    for category, patterns in sarcasm_patterns.items():\n",
    "        for pattern, weight in patterns:\n",
    "            matches = df['review'].str.contains(pattern, case=False, na=False, regex=True)\n",
    "            df.loc[matches, 'sarcasm_score'] += weight\n",
    "            df.loc[matches, 'sarcasm_indicators'] += f\"{category}; \"\n",
    "    \n",
    "    # Additional heuristics based on Steam-specific features\n",
    "    if 'voted_up' in df.columns and 'votes_funny' in df.columns:\n",
    "        # Negative reviews with high funny votes are likely sarcastic\n",
    "        funny_negative = (df['voted_up'] == False) & (df['votes_funny'] > df['votes_funny'].quantile(0.7))\n",
    "        df.loc[funny_negative, 'sarcasm_score'] += 1.0\n",
    "        df.loc[funny_negative, 'sarcasm_indicators'] += 'funny_negative; '\n",
    "    \n",
    "    # Detect excessive punctuation and caps (sarcasm indicators)\n",
    "    df['caps_ratio'] = df['review'].apply(lambda x: sum(1 for c in str(x) if c.isupper()) / len(str(x)) if len(str(x)) > 0 else 0)\n",
    "    df['exclamation_count'] = df['review'].str.count('!')\n",
    "    df['question_count'] = df['review'].str.count('\\?')\n",
    "    \n",
    "    # High caps ratio with positive words might indicate sarcasm\n",
    "    high_caps = df['caps_ratio'] > 0.3\n",
    "    df.loc[high_caps, 'sarcasm_score'] += 0.5\n",
    "    df.loc[high_caps, 'sarcasm_indicators'] += 'high_caps; '\n",
    "    \n",
    "    # Multiple exclamation marks with negative sentiment\n",
    "    excessive_exclamation = df['exclamation_count'] > 2\n",
    "    df.loc[excessive_exclamation, 'sarcasm_score'] += 0.3\n",
    "    df.loc[excessive_exclamation, 'sarcasm_indicators'] += 'excessive_punct; '\n",
    "    \n",
    "    # Use VADER sentiment to detect polarity mismatches\n",
    "    print(\"ðŸ” Analyzing sentiment for sarcasm detection...\")\n",
    "    sentiment_scores = df['review'].apply(lambda x: analyzer.polarity_scores(str(x)))\n",
    "    df['vader_positive'] = [score['pos'] for score in sentiment_scores]\n",
    "    df['vader_negative'] = [score['neg'] for score in sentiment_scores]\n",
    "    df['vader_compound'] = [score['compound'] for score in sentiment_scores]\n",
    "    \n",
    "    # High positive words but negative overall sentiment (potential sarcasm)\n",
    "    polarity_mismatch = (df['vader_positive'] > 0.3) & (df['vader_compound'] < -0.1)\n",
    "    df.loc[polarity_mismatch, 'sarcasm_score'] += 1.2\n",
    "    df.loc[polarity_mismatch, 'sarcasm_indicators'] += 'polarity_mismatch; '\n",
    "    \n",
    "    # Create binary sarcasm labels based on score threshold\n",
    "    sarcasm_threshold = df['sarcasm_score'].quantile(0.35)  # Top 65% as sarcastic\n",
    "    df['is_sarcastic'] = (df['sarcasm_score'] >= sarcasm_threshold).astype(int)\n",
    "    df['label'] = df['is_sarcastic']\n",
    "    df['sentiment'] = df['is_sarcastic'].map({1: 'sarcastic', 0: 'genuine'})\n",
    "    \n",
    "    print(f\"ðŸ“Š Sarcasm Detection Results:\")\n",
    "    print(f\"Sarcasm threshold: {sarcasm_threshold:.2f}\")\n",
    "    print(f\"Distribution: {df['sentiment'].value_counts().to_dict()}\")\n",
    "    print(f\"Total reviews: {len(df)}\")\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset_for_training(df, target_size=1200):\n",
    "    \"\"\"\n",
    "    Prepare the dataset for training with balanced sampling\n",
    "    \"\"\"\n",
    "    if df is None or len(df) == 0:\n",
    "        print(\"âŒ No data available for training\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"ðŸ“Š Preparing dataset from {len(df)} reviews...\")\n",
    "    \n",
    "    # Clean the data\n",
    "    df = df.dropna(subset=['review'])\n",
    "    df = df[df['review'].str.len() > 10]  # Remove very short reviews\n",
    "    \n",
    "    # Sample data if we have too many reviews\n",
    "    if len(df) > target_size:\n",
    "        print(f\"ðŸ“‰ Sampling {target_size} reviews from {len(df)} total...\")\n",
    "        \n",
    "        # Try to maintain balance between sarcastic and genuine\n",
    "        if 'label' in df.columns:\n",
    "            sarcastic_target = int(target_size * 0.65)  # 65% sarcastic\n",
    "            genuine_target = target_size - sarcastic_target\n",
    "            \n",
    "            sarcastic_reviews = df[df['label'] == 1]\n",
    "            genuine_reviews = df[df['label'] == 0]\n",
    "            \n",
    "            # Sample from each group\n",
    "            if len(sarcastic_reviews) >= sarcastic_target:\n",
    "                sarcastic_sample = sarcastic_reviews.sample(n=sarcastic_target, random_state=42)\n",
    "            else:\n",
    "                sarcastic_sample = sarcastic_reviews\n",
    "            \n",
    "            if len(genuine_reviews) >= genuine_target:\n",
    "                genuine_sample = genuine_reviews.sample(n=genuine_target, random_state=42)\n",
    "            else:\n",
    "                genuine_sample = genuine_reviews\n",
    "            \n",
    "            df = pd.concat([sarcastic_sample, genuine_sample]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "        else:\n",
    "            df = df.sample(n=target_size, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"âœ… Final dataset: {len(df)} reviews\")\n",
    "    if 'sentiment' in df.columns:\n",
    "        print(f\"ðŸ“ˆ Final distribution: {df['sentiment'].value_counts().to_dict()}\")\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SarcasmAwarePreprocessor:\n",
    "    \"\"\"\n",
    "    Advanced text preprocessor specifically designed for Steam review sarcasm detection\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "        # Preserve negation and intensifier words\n",
    "        self.preserve_words = {\n",
    "            'not', 'no', 'never', 'nothing', 'nobody', 'nowhere', 'neither', 'nor', \n",
    "            'barely', 'hardly', 'scarcely', 'very', 'so', 'extremely', 'totally', \n",
    "            'absolutely', 'completely', 'quite', 'rather', 'really', 'definitely',\n",
    "            'certainly', 'obviously', 'clearly', 'surely'\n",
    "        }\n",
    "        self.stop_words = self.stop_words - self.preserve_words\n",
    "        \n",
    "        # Steam/Gaming specific terms to preserve\n",
    "        self.gaming_terms = {\n",
    "            'dlc', 'fps', 'gameplay', 'multiplayer', 'singleplayer', 'coop', 'pvp',\n",
    "            'respawn', 'checkpoint', 'save', 'load', 'crash', 'bug', 'glitch', \n",
    "            'lag', 'ping', 'server', 'patch', 'update', 'nerf', 'buff', 'op',\n",
    "            'ragequit', 'noob', 'pro', 'speedrun', 'achievements', 'trophies'\n",
    "        }\n",
    "    \n",
    "    def extract_advanced_sarcasm_features(self, text):\n",
    "        \"\"\"\n",
    "        Extract comprehensive sarcasm detection features\n",
    "        \"\"\"\n",
    "        if not isinstance(text, str):\n",
    "            text = str(text)\n",
    "        \n",
    "        features = {}\n",
    "        text_lower = text.lower()\n",
    "        words = text.split()\n",
    "        \n",
    "        # Basic text statistics\n",
    "        features['word_count'] = len(words)\n",
    "        features['char_count'] = len(text)\n",
    "        features['avg_word_length'] = np.mean([len(word) for word in words]) if words else 0\n",
    "        features['sentence_count'] = len(re.split(r'[.!?]+', text))\n",
    "        \n",
    "        # Capitalization patterns (often used in sarcasm)\n",
    "        features['caps_ratio'] = sum(1 for c in text if c.isupper()) / len(text) if text else 0\n",
    "        features['caps_words'] = sum(1 for word in words if word.isupper())\n",
    "        features['caps_sequences'] = len(re.findall(r'[A-Z]{3,}', text))\n",
    "        \n",
    "        # Punctuation patterns (excessive punctuation in sarcasm)\n",
    "        features['exclamation_count'] = text.count('!')\n",
    "        features['question_count'] = text.count('?')\n",
    "        features['ellipsis_count'] = len(re.findall(r'\\.{3,}', text))\n",
    "        features['multiple_punct'] = len(re.findall(r'[!?]{2,}', text))\n",
    "        features['punct_density'] = sum([features['exclamation_count'], features['question_count'], \n",
    "                                       features['ellipsis_count']]) / len(text) if text else 0\n",
    "        \n",
    "        # Sentiment analysis scores\n",
    "        sentiment_scores = analyzer.polarity_scores(text)\n",
    "        features.update({f'vader_{k}': v for k, v in sentiment_scores.items()})\n",
    "        \n",
    "        # Advanced sarcasm indicators\n",
    "        features['intensifier_count'] = sum(1 for word in text_lower.split() \n",
    "                                          if word in ['very', 'so', 'extremely', 'totally', 'absolutely', \n",
    "                                                    'completely', 'quite', 'rather', 'really', 'definitely'])\n",
    "        \n",
    "        # Contradiction patterns\n",
    "        positive_words = ['great', 'amazing', 'excellent', 'fantastic', 'wonderful', 'perfect', \n",
    "                         'brilliant', 'outstanding', 'superb', 'best', 'love', 'awesome']\n",
    "        negative_words = ['terrible', 'awful', 'horrible', 'worst', 'hate', 'broken', 'crash', \n",
    "                         'bug', 'glitch', 'frustrating', 'annoying', 'impossible']\n",
    "        \n",
    "        features['positive_word_count'] = sum(1 for word in positive_words if word in text_lower)\n",
    "        features['negative_word_count'] = sum(1 for word in negative_words if word in text_lower)\n",
    "        features['pos_neg_cooccurrence'] = 1 if features['positive_word_count'] > 0 and features['negative_word_count'] > 0 else 0\n",
    "        \n",
    "        # Steam-specific sarcasm patterns\n",
    "        steam_sarcasm_patterns = [\n",
    "            r'10/10.*would.*(?:rage|quit|crash|never)',\n",
    "            r'perfect.*(?:if you enjoy|for people who)',\n",
    "            r'great.*(?:if you like|when you)',\n",
    "            r'love.*how.*(?:crash|bug|glitch)',\n",
    "            r'amazing.*(?:graphics|sound).*(?:from|like).*(?:199\\d|200\\d)',\n",
    "            r'excellent.*(?:tutorial|help).*(?:hours|still|never)',\n",
    "            r'who needs.*(?:tutorial|help|balance)',\n",
    "            r'nothing like.*getting.*(?:owned|destroyed|rekt)',\n",
    "            r'highly recommend.*(?:if you|for people who).*(?:enjoy|like).*(?:pain|suffering|frustration)'\n",
    "        ]\n",
    "        \n",
    "        features['steam_sarcasm_count'] = sum(1 for pattern in steam_sarcasm_patterns \n",
    "                                            if re.search(pattern, text_lower))\n",
    "        \n",
    "        # Gaming terminology\n",
    "        features['gaming_terms_count'] = sum(1 for term in self.gaming_terms if term in text_lower)\n",
    "        \n",
    "        # Quotation marks (often used sarcastically)\n",
    "        features['quote_count'] = text.count('\"') + text.count(\"'\")\n",
    "        \n",
    "        # All caps words (emphasis in sarcasm)\n",
    "        features['all_caps_words'] = len(re.findall(r'\\b[A-Z]{2,}\\b', text))\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Comprehensive text preprocessing for sarcasm detection\n",
    "        \"\"\"\n",
    "        if not isinstance(text, str):\n",
    "            text = str(text)\n",
    "        \n",
    "        # Extract features before preprocessing\n",
    "        features = self.extract_advanced_sarcasm_features(text)\n",
    "        \n",
    "        # Preserve important patterns before cleaning\n",
    "        text = re.sub(r'(\\d+)/(\\d+)', r'RATING_\\1_\\2', text)  # Preserve ratings like 10/10\n",
    "        text = re.sub(r'[.]{3,}', ' ELLIPSIS ', text)\n",
    "        text = re.sub(r'[!]{2,}', ' MULTIPLE_EXCLAMATION ', text)\n",
    "        text = re.sub(r'[?]{2,}', ' MULTIPLE_QUESTION ', text)\n",
    "        \n",
    "        # Clean URLs, mentions, etc.\n",
    "        text = re.sub(r'http\\S+', '', text)\n",
    "        text = re.sub(r'@\\w+', '', text)\n",
    "        text = re.sub(r'#\\w+', '', text)\n",
    "        \n",
    "        # Preserve negation context\n",
    "        negation_patterns = [\n",
    "            (r'\\b(not|no|never|nothing|nobody|nowhere|neither|nor)\\s+(\\w+)', r'\\1_\\2'),\n",
    "            (r'\\b(barely|hardly|scarcely)\\s+(\\w+)', r'\\1_\\2'),\n",
    "            (r'\\b(can\\'t|cannot|won\\'t|wouldn\\'t|shouldn\\'t|couldn\\'t)\\s+(\\w+)', r'\\1_\\2'),\n",
    "            (r'\\b(don\\'t|doesn\\'t|didn\\'t)\\s+(\\w+)', r'\\1_\\2')\n",
    "        ]\n",
    "        \n",
    "        for pattern, replacement in negation_patterns:\n",
    "            text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)\n",
    "        \n",
    "        # Tokenize and clean\n",
    "        tokens = nltk.word_tokenize(text.lower())\n",
    "        \n",
    "        # Remove stopwords but preserve important words\n",
    "        tokens = [token for token in tokens \n",
    "                 if token not in self.stop_words or token in self.preserve_words or token in self.gaming_terms]\n",
    "        \n",
    "        # Keep alphabetic tokens and preserved special tokens\n",
    "        special_tokens = ['ELLIPSIS', 'MULTIPLE_EXCLAMATION', 'MULTIPLE_QUESTION'] + [f'RATING_{i}_{j}' for i in range(1, 11) for j in range(1, 11)]\n",
    "        tokens = [token for token in tokens \n",
    "                 if token.isalpha() or token in special_tokens or '_' in token]\n",
    "        \n",
    "        clean_text = ' '.join(tokens)\n",
    "        \n",
    "        return clean_text, features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main execution pipeline for real Steam reviews sarcasm detection\n",
    "    \"\"\"\n",
    "    print(\"ðŸš€ Starting Real Steam Reviews Sarcasm Detection Pipeline\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Step 1: Load real dataset\n",
    "    df_raw = load_real_steam_dataset()\n",
    "    \n",
    "    if df_raw is None:\n",
    "        print(\"âŒ Could not load dataset. Please check your setup.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Raw dataset loaded: {df_raw.shape}\")\n",
    "    print(f\"Columns: {list(df_raw.columns)}\")\n",
    "    \n",
    "    # Step 2: Identify sarcastic reviews\n",
    "    df_labeled = identify_sarcastic_reviews(df_raw)\n",
    "    \n",
    "    # Step 3: Prepare for training\n",
    "    df = prepare_dataset_for_training(df_labeled, target_size=1200)\n",
    "    \n",
    "    if df is None:\n",
    "        print(\"âŒ Could not prepare dataset for training.\")\n",
    "        return\n",
    "    \n",
    "    # Step 4: Advanced preprocessing\n",
    "    print(\"\\nðŸ”§ Applying advanced preprocessing...\")\n",
    "    preprocessor = SarcasmAwarePreprocessor()\n",
    "    \n",
    "    results = df['review'].apply(lambda x: preprocessor.preprocess_text(x))\n",
    "    df['clean_review'] = [result[0] for result in results]\n",
    "    features_list = [result[1] for result in results]\n",
    "    \n",
    "    # Convert features to DataFrame\n",
    "    features_df = pd.DataFrame(features_list)\n",
    "    df = pd.concat([df, features_df], axis=1)\n",
    "    \n",
    "    print(f\"âœ… Preprocessing completed!\")\n",
    "    print(f\"Added {len(features_df.columns)} advanced features\")\n",
    "    \n",
    "    # Step 5: Create feature matrix\n",
    "    print(\"\\nðŸŽ¯ Creating feature matrices...\")\n",
    "    \n",
    "    # TF-IDF features\n",
    "    tfidf = TfidfVectorizer(\n",
    "        max_features=3000,\n",
    "        ngram_range=(1, 3),\n",
    "        min_df=2,\n",
    "        max_df=0.9,\n",
    "        sublinear_tf=True\n",
    "    )\n",
    "    \n",
    "    X_tfidf = tfidf.fit_transform(df['clean_review'])\n",
    "    \n",
    "    # Numerical features\n",
    "    feature_cols = [col for col in features_df.columns if isinstance(df[col].iloc[0], (int, float))]\n",
    "    X_numerical = df[feature_cols].fillna(0)\n",
    "    \n",
    "    # Combine features\n",
    "    from scipy.sparse import hstack\n",
    "    import scipy.sparse as sp\n",
    "    X_combined = hstack([X_tfidf, sp.csr_matrix(X_numerical.values)])\n",
    "    \n",
    "    y = df['label'].values\n",
    "    \n",
    "    print(f\"ðŸ“ˆ Feature matrix shape: {X_combined.shape}\")\n",
    "    print(f\"ðŸ·ï¸ Label distribution: Sarcastic: {sum(y)}, Genuine: {len(y) - sum(y)}\")\n",
    "    \n",
    "    # Step 6: Train models\n",
    "    print(\"\\nðŸ¤– Training models...\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_combined, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    models = {\n",
    "        'Naive Bayes': MultinomialNB(alpha=0.1),\n",
    "        'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000, C=1.0),\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"Training {name}...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        \n",
    "        results[name] = {\n",
    "            'Accuracy': accuracy,\n",
    "            'F1-Score': f1,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall\n",
    "        }\n",
    "        \n",
    "        print(f\"âœ… {name} - Accuracy: {accuracy:.3f}, F1: {f1:.3f}\")\n",
    "    \n",
    "    # Step 7: Display results\n",
    "    print(\"\\nðŸ“Š FINAL RESULTS:\")\n",
    "    print(\"=\" * 50)\n",
    "    results_df = pd.DataFrame(results).round(3)\n",
    "    print(results_df)\n",
    "    \n",
    "    # Find best model\n",
    "    best_model = results_df.loc['F1-Score'].idxmax()\n",
    "    best_f1 = results_df.loc['F1-Score', best_model]\n",
    "    \n",
    "    print(f\"\\nðŸ† Best Model: {best_model}\")\n",
    "    print(f\"ðŸŽ¯ Best F1 Score: {best_f1}\")\n",
    "    \n",
    "    # Step 8: Show example predictions\n",
    "    print(\"\\nðŸ” Example Predictions:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    best_model_obj = models[best_model]\n",
    "    sample_indices = np.random.choice(len(X_test), 5, replace=False)\n",
    "    \n",
    "    for idx in sample_indices:\n",
    "        prediction = best_model_obj.predict(X_test[idx])[0]\n",
    "        actual = y_test[idx]\n",
    "        review_text = df.iloc[X_test.indices[idx] if hasattr(X_test, 'indices') else idx]['review'][:100]\n",
    "        \n",
    "        print(f\"Review: {review_text}...\")\n",
    "        print(f\"Predicted: {'Sarcastic' if prediction == 1 else 'Genuine'}\")\n",
    "        print(f\"Actual: {'Sarcastic' if actual == 1 else 'Genuine'}\")\n",
    "        print(\"-\" * 40)\n",
    "    \n",
    "    print(\"\\nðŸŽ‰ Analysis completed successfully!\")\n",
    "    \n",
    "    return df, results_df, models[best_model]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting Real Steam Reviews Sarcasm Detection Pipeline\n",
      "============================================================\n",
      "ðŸ“¥ Loading real Steam Reviews dataset...\n",
      "ðŸ”„ Trying kaggle dataset...\n",
      "zsh:1: command not found: kaggle\n",
      "âŒ Failed to load from kaggle: [Errno 2] No such file or directory: 'steam_reviews.csv'\n",
      "ðŸ”„ Trying kaggle dataset...\n",
      "zsh:1: command not found: kaggle\n",
      "âŒ Failed to load from kaggle: [Errno 2] No such file or directory: 'steam_reviews.csv'\n",
      "ðŸ”„ Trying kaggle dataset...\n",
      "zsh:1: command not found: kaggle\n",
      "âŒ Failed to load from kaggle: [Errno 2] No such file or directory: 'steam_reviews_2021.csv'\n",
      "ðŸ“ Please upload your Steam reviews CSV file manually\n",
      "Expected columns: review_text, voted_up, votes_helpful, votes_funny, playtime_forever\n",
      "âŒ Could not load dataset. Please check your setup.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Run the main pipeline\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 3\u001b[0m     df_final, results_final, best_model_final \u001b[38;5;241m=\u001b[39m main()\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "# Run the main pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    df_final, results_final, best_model_final = main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
